"""Extract performance metrics from PyTorch profiler trace files.

This script analyzes Chrome trace format JSON files generated by torch.profiler
to extract key performance metrics for bottleneck analysis.

Usage:
    # Analyze all traces from a run
    python scripts/detect_bottlenecks.py <experiment_name> <run_id> [--json]

    # Analyze a single trace file (legacy)
    python scripts/detect_bottlenecks.py <path_to_trace_json> [--json]

Output format:
    Structured metrics including timing breakdowns, top operations,
    and ratios for determining bottlenecks.
"""

import argparse
import json
import sys
from collections import defaultdict
from dataclasses import dataclass, field
from pathlib import Path

import numpy as np
from utils.run_discovery import resolve_trace_paths


@dataclass
class TraceMetrics:
    """Extracted performance metrics from trace analysis."""

    # Timeline (microseconds)
    trace_duration_us: float
    global_start_us: float
    global_end_us: float

    # Category times (microseconds)
    cpu_op_time_us: float
    gpu_kernel_time_us: float
    data_loading_time_us: float
    compute_time_us: float
    dataloader_wait_time_us: float  # Time blocked waiting for dataloader workers

    # Counts
    total_events: int
    cpu_op_count: int
    gpu_kernel_count: int

    # Ratios (useful for bottleneck detection)
    cpu_gpu_ratio: float  # cpu_time / gpu_time
    data_compute_ratio: float  # data_time / compute_time
    gpu_utilization_pct: float  # gpu_time / trace_duration
    worker_saturation_pct: float  # % of dataloader events that are >100ms (indicates worker bottleneck)

    # Top operations (name, duration_us, count)
    top_cpu_ops: list[tuple[str, float, int]] = field(default_factory=list)
    top_gpu_kernels: list[tuple[str, float, int]] = field(default_factory=list)
    top_data_ops: list[tuple[str, float, int]] = field(default_factory=list)

    # Per-category breakdown
    cpu_ops_by_name: dict[str, tuple[float, int]] = field(default_factory=dict)
    gpu_kernels_by_name: dict[str, tuple[float, int]] = field(default_factory=dict)

    # Event categories found
    categories: set[str] = field(default_factory=set)


def extract_metrics(trace_path: str) -> TraceMetrics:
    """Extract metrics from Chrome trace JSON file."""
    with open(trace_path) as f:
        try:
            data = json.load(f)
        except json.JSONDecodeError as e:
            print(f"Error decoding JSON: {e}", file=sys.stderr)
            sys.exit(1)

    events = data.get("traceEvents", [])
    if not events:
        print("No traceEvents found in file.", file=sys.stderr)
        sys.exit(1)

    # Aggregators
    op_duration: defaultdict[str, float] = defaultdict(float)
    op_count: defaultdict[str, int] = defaultdict(int)

    # Timeline tracking
    start_times = []
    end_times = []

    # Categories
    categories = set()

    # Track dataloader waits separately
    dataloader_waits: list[float] = []

    # Keywords for categorization
    data_ops_keywords = {
        "dataloader",
        "collate",
        "worker",
        "enqueue",
        "index",
        "slice",
        "getitem",
        "mkl",
        "numpy",
        "prefetch",
        "batch",
        "enumerate",  # Catch dataloader wait events (enumerate(DataLoader).__next__)
    }

    for event in events:
        if "dur" not in event:
            continue

        name = event.get("name", "unknown")
        cat = event.get("cat", "unknown")
        duration_us = event["dur"]
        name_lower = name.lower()

        categories.add(cat)

        # Track timeline
        if "ts" in event:
            start_times.append(event["ts"])
            end_times.append(event["ts"] + duration_us)

        # Track dataloader waits separately (enumerate(DataLoader).__next__ events)
        if "enumerate" in name_lower and "dataloader" in name_lower:
            dataloader_waits.append(duration_us)

        key = f"[{cat}] {name}"
        op_duration[key] += duration_us
        op_count[key] += 1

    # Calculate timeline
    global_start_us = min(start_times) if start_times else 0
    global_end_us = max(end_times) if end_times else 0
    trace_duration_us = global_end_us - global_start_us

    # Separate and categorize operations
    cpu_ops = []
    gpu_kernels = []
    data_ops = []
    cpu_time_us = 0.0
    gpu_time_us = 0.0
    data_time_us = 0.0
    compute_time_us = 0.0

    for key, dur in op_duration.items():
        count = op_count[key]
        clean_name = key.split("] ", 1)[1] if "] " in key else key
        name_lower = clean_name.lower()

        if key.startswith("[cpu_op]"):
            is_data = any(kw in name_lower for kw in data_ops_keywords)
            if is_data:
                data_ops.append((clean_name, dur, count))
                data_time_us += dur
            else:
                cpu_ops.append((clean_name, dur, count))
                cpu_time_us += dur
                compute_time_us += dur
        elif key.startswith("[kernel]"):
            gpu_kernels.append((clean_name, dur, count))
            gpu_time_us += dur

    # Sort by duration
    cpu_ops.sort(key=lambda x: x[1], reverse=True)
    gpu_kernels.sort(key=lambda x: x[1], reverse=True)
    data_ops.sort(key=lambda x: x[1], reverse=True)

    # Build dictionaries
    cpu_ops_by_name = {name: (dur, count) for name, dur, count in cpu_ops}
    gpu_kernels_by_name = {name: (dur, count) for name, dur, count in gpu_kernels}

    # Calculate ratios
    cpu_gpu_ratio = cpu_time_us / gpu_time_us if gpu_time_us > 0 else float("inf")
    data_compute_ratio = data_time_us / compute_time_us if compute_time_us > 0 else float("inf")
    gpu_utilization_pct = (gpu_time_us / trace_duration_us * 100) if trace_duration_us > 0 else 0

    # Calculate dataloader-specific metrics
    dataloader_wait_time_us = sum(dataloader_waits)
    if dataloader_waits:
        long_waits = sum(1 for w in dataloader_waits if w > 100_000)  # >100ms indicates worker saturation
        worker_saturation_pct = (long_waits / len(dataloader_waits)) * 100
    else:
        worker_saturation_pct = 0.0

    return TraceMetrics(
        trace_duration_us=trace_duration_us,
        global_start_us=global_start_us,
        global_end_us=global_end_us,
        cpu_op_time_us=cpu_time_us,
        gpu_kernel_time_us=gpu_time_us,
        data_loading_time_us=data_time_us,
        compute_time_us=compute_time_us,
        dataloader_wait_time_us=dataloader_wait_time_us,
        total_events=len(events),
        cpu_op_count=len(cpu_ops),
        gpu_kernel_count=len(gpu_kernels),
        cpu_gpu_ratio=cpu_gpu_ratio,
        data_compute_ratio=data_compute_ratio,
        gpu_utilization_pct=gpu_utilization_pct,
        worker_saturation_pct=worker_saturation_pct,
        top_cpu_ops=cpu_ops[:20],
        top_gpu_kernels=gpu_kernels[:20],
        top_data_ops=data_ops[:20],
        cpu_ops_by_name=cpu_ops_by_name,
        gpu_kernels_by_name=gpu_kernels_by_name,
        categories=categories,
    )


def format_text(metrics: TraceMetrics) -> str:
    """Format metrics as readable text."""
    lines = [
        "=" * 70,
        "TRACE METRICS EXTRACTED",
        "=" * 70,
        "",
        f"Trace file:        {metrics.trace_duration_us:.0f} us total duration",
        f"Total events:      {metrics.total_events}",
        f"Categories:        {sorted(metrics.categories)}",
        "",
        "TIMING BREAKDOWN (microseconds)",
        "-" * 70,
        f"CPU op time:       {metrics.cpu_op_time_us:>12.0f} us  ({metrics.cpu_op_time_us / metrics.trace_duration_us * 100:>5.1f}% of trace)",
        f"GPU kernel time:   {metrics.gpu_kernel_time_us:>12.0f} us  ({metrics.gpu_kernel_time_us / metrics.trace_duration_us * 100:>5.1f}% of trace)",
        f"Data loading:      {metrics.data_loading_time_us:>12.0f} us  ({metrics.data_loading_time_us / metrics.trace_duration_us * 100:>5.1f}% of trace)",
        f"Compute time:      {metrics.compute_time_us:>12.0f} us  ({metrics.compute_time_us / metrics.trace_duration_us * 100:>5.1f}% of trace)",
        "",
        "KEY RATIOS",
        "-" * 70,
        f"CPU/GPU ratio:     {metrics.cpu_gpu_ratio:>12.2f}",
        f"Data/Compute:      {metrics.data_compute_ratio:>12.2f}",
        f"GPU utilization:   {metrics.gpu_utilization_pct:>12.1f}%",
        "",
        "DATALOADER ANALYSIS",
        "-" * 70,
        f"Dataloader wait:   {metrics.dataloader_wait_time_us:>12.0f} us  ({metrics.dataloader_wait_time_us / metrics.trace_duration_us * 100:>5.1f}% of trace)",
        f"Worker saturation: {metrics.worker_saturation_pct:>12.1f}%",
        "",
    ]

    # Add interpretation/warnings for worker saturation
    if metrics.worker_saturation_pct > 50:
        lines.append("⚠️  WORKERS SATURATED: Consider increasing num_workers")
    elif metrics.dataloader_wait_time_us / metrics.trace_duration_us > 0.3:
        lines.append("⚠️  DATALOADER BOTTLENECK: Workers can't keep up with GPU")

    lines.extend([
        "",
        "TOP 10 GPU KERNELS (name | total_us | count | avg_us)",
        "-" * 70,
    ])

    if metrics.top_gpu_kernels:
        for name, dur_us, count in metrics.top_gpu_kernels[:10]:
            avg_us = dur_us / count if count > 0 else 0
            lines.append(f"{name[:45]:<45} | {dur_us:>10.0f} | {count:>4} | {avg_us:>8.1f}")
    else:
        lines.append("(No GPU kernels found)")

    lines.extend([
        "",
        "TOP 10 CPU OPS (name | total_us | count | avg_us)",
        "-" * 70,
    ])

    if metrics.top_cpu_ops:
        for name, dur_us, count in metrics.top_cpu_ops[:10]:
            avg_us = dur_us / count if count > 0 else 0
            lines.append(f"{name[:45]:<45} | {dur_us:>10.0f} | {count:>4} | {avg_us:>8.1f}")
    else:
        lines.append("(No CPU ops found)")

    if metrics.top_data_ops:
        lines.extend([
            "",
            "TOP DATA LOADING OPS (name | total_us | count | avg_us)",
            "-" * 70,
        ])
        for name, dur_us, count in metrics.top_data_ops[:10]:
            avg_us = dur_us / count if count > 0 else 0
            lines.append(f"{name[:45]:<45} | {dur_us:>10.0f} | {count:>4} | {avg_us:>8.1f}")

    lines.append("=" * 70)
    return "\n".join(lines)


def format_json(metrics: TraceMetrics) -> str:
    """Format metrics as JSON for programmatic parsing."""
    # Convert to dict with serializable types
    data = {
        "trace_duration_us": metrics.trace_duration_us,
        "global_start_us": metrics.global_start_us,
        "global_end_us": metrics.global_end_us,
        "cpu_op_time_us": metrics.cpu_op_time_us,
        "gpu_kernel_time_us": metrics.gpu_kernel_time_us,
        "data_loading_time_us": metrics.data_loading_time_us,
        "compute_time_us": metrics.compute_time_us,
        "dataloader_wait_time_us": metrics.dataloader_wait_time_us,
        "total_events": metrics.total_events,
        "cpu_op_count": metrics.cpu_op_count,
        "gpu_kernel_count": metrics.gpu_kernel_count,
        "cpu_gpu_ratio": metrics.cpu_gpu_ratio,
        "data_compute_ratio": metrics.data_compute_ratio,
        "gpu_utilization_pct": metrics.gpu_utilization_pct,
        "worker_saturation_pct": metrics.worker_saturation_pct,
        "categories": sorted(metrics.categories),
        "top_cpu_ops": [
            {"name": n, "duration_us": d, "count": c}
            for n, d, c in metrics.top_cpu_ops
        ],
        "top_gpu_kernels": [
            {"name": n, "duration_us": d, "count": c}
            for n, d, c in metrics.top_gpu_kernels
        ],
        "top_data_ops": [
            {"name": n, "duration_us": d, "count": c}
            for n, d, c in metrics.top_data_ops
        ],
    }
    return json.dumps(data, indent=2)


def format_aggregated_text(
    all_metrics: list[tuple[Path, TraceMetrics]], experiment_name: str, run_id: str
) -> str:
    """Format aggregated metrics from multiple traces as readable text."""
    lines = [
        "=" * 70,
        f"TRACE METRICS EXTRACTED ({len(all_metrics)} traces)",
        "=" * 70,
        "",
        f"Experiment: {experiment_name}",
        f"Run: {run_id}",
        f"Traces found: {len(all_metrics)}",
        "",
    ]

    # Calculate aggregate statistics
    durations = [m.trace_duration_us for _, m in all_metrics]
    gpu_utils = [m.gpu_utilization_pct for _, m in all_metrics]
    cpu_gpu_ratios = [m.cpu_gpu_ratio for _, m in all_metrics]
    data_compute_ratios = [m.data_compute_ratio for _, m in all_metrics]
    dataloader_waits = [m.dataloader_wait_time_us for _, m in all_metrics]
    worker_saturations = [m.worker_saturation_pct for _, m in all_metrics]

    lines.extend([
        "AGGREGATE METRICS (mean ± std)",
        "-" * 70,
        f"Trace duration:    {np.mean(durations):>12.0f} ± {np.std(durations):>8.0f} us",
        f"GPU utilization:   {np.mean(gpu_utils):>8.1f} ± {np.std(gpu_utils):>4.1f} %",
        f"CPU/GPU ratio:     {np.mean(cpu_gpu_ratios):>8.2f} ± {np.std(cpu_gpu_ratios):>4.2f}",
        f"Data/Compute:      {np.mean(data_compute_ratios):>8.2f} ± {np.std(data_compute_ratios):>4.2f}",
        f"Dataloader wait:   {np.mean(dataloader_waits):>12.0f} ± {np.std(dataloader_waits):>8.0f} us",
        f"Worker saturation: {np.mean(worker_saturations):>8.1f} ± {np.std(worker_saturations):>4.1f} %",
        "",
        "PER-TRACE BREAKDOWN",
        "-" * 70,
    ])

    for i, (trace_path, metrics) in enumerate(all_metrics, 1):
        trace_name = trace_path.stem[:40]  # Truncate long names
        lines.extend([
            f"Trace {i} ({trace_name}):",
            f"  Duration: {metrics.trace_duration_us / 1000:.1f} ms, "
            f"GPU util: {metrics.gpu_utilization_pct:.1f}%, "
            f"CPU/GPU: {metrics.cpu_gpu_ratio:.2f}",
            f"  Dataloader wait: {metrics.dataloader_wait_time_us / 1000:.1f} ms, "
            f"Worker saturation: {metrics.worker_saturation_pct:.1f}%",
        ])

        # Top 3 kernels for this trace
        if metrics.top_gpu_kernels:
            lines.append("  Top GPU kernels:")
            for name, dur_us, _count in metrics.top_gpu_kernels[:3]:
                lines.append(f"    - {name[:35]:<35} {dur_us / 1000:>6.1f} ms")

    lines.append("=" * 70)
    return "\n".join(lines)


def format_aggregated_json(
    all_metrics: list[tuple[Path, TraceMetrics]], experiment_name: str, run_id: str
) -> str:
    """Format aggregated metrics as JSON."""
    aggregated = {
        "experiment_name": experiment_name,
        "run_id": run_id,
        "trace_count": len(all_metrics),
        "traces": [],
    }

    # Aggregate statistics
    durations = [m.trace_duration_us for _, m in all_metrics]
    gpu_utils = [m.gpu_utilization_pct for _, m in all_metrics]
    cpu_gpu_ratios = [m.cpu_gpu_ratio for _, m in all_metrics]
    dataloader_waits = [m.dataloader_wait_time_us for _, m in all_metrics]
    worker_saturations = [m.worker_saturation_pct for _, m in all_metrics]

    aggregated["aggregate_stats"] = {
        "trace_duration_us": {"mean": float(np.mean(durations)), "std": float(np.std(durations))},
        "gpu_utilization_pct": {"mean": float(np.mean(gpu_utils)), "std": float(np.std(gpu_utils))},
        "cpu_gpu_ratio": {"mean": float(np.mean(cpu_gpu_ratios)), "std": float(np.std(cpu_gpu_ratios))},
        "dataloader_wait_time_us": {"mean": float(np.mean(dataloader_waits)), "std": float(np.std(dataloader_waits))},
        "worker_saturation_pct": {"mean": float(np.mean(worker_saturations)), "std": float(np.std(worker_saturations))},
    }

    for trace_path, metrics in all_metrics:
        trace_data = json.loads(format_json(metrics))
        trace_data["trace_name"] = trace_path.stem
        aggregated["traces"].append(trace_data)

    return json.dumps(aggregated, indent=2)


def main():
    parser = argparse.ArgumentParser(
        description="Extract performance metrics from PyTorch profiler trace",
        epilog="""
Examples:
  # Analyze all traces from a run
  perf-analyze mn5_epiforecaster_full 34198361

  # Analyze a single trace file
  perf-analyze outputs/training/mn5_epiforecaster_full/34198361/trace.json
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "inputs",
        nargs="+",
        help="Either: experiment_name run_id OR path to single trace JSON file",
    )
    parser.add_argument(
        "--json", action="store_true", help="Output as JSON instead of text"
    )

    args = parser.parse_args()

    # Determine input mode
    if len(args.inputs) == 2:
        # Experiment + run ID mode
        experiment_name, run_id = args.inputs
        try:
            trace_paths = resolve_trace_paths(experiment_name=experiment_name, run_id=run_id)
        except FileNotFoundError as e:
            print(f"Error: {e}", file=sys.stderr)
            sys.exit(1)
    elif len(args.inputs) == 1:
        # Single file mode (backward compatible)
        trace_path = Path(args.inputs[0])
        if not trace_path.exists():
            print(f"Error: Trace file not found: {trace_path}", file=sys.stderr)
            sys.exit(1)
        trace_paths = [trace_path]
        experiment_name = run_id = None
    else:
        parser.print_help()
        sys.exit(1)

    # Extract metrics from all traces
    all_metrics: list[tuple[Path, TraceMetrics]] = []
    for trace_path in trace_paths:
        try:
            metrics = extract_metrics(str(trace_path))
            all_metrics.append((trace_path, metrics))
        except Exception as e:
            print(f"Warning: Failed to analyze {trace_path}: {e}", file=sys.stderr)

    if not all_metrics:
        print("Error: No valid traces found", file=sys.stderr)
        sys.exit(1)

    # Output
    if len(all_metrics) == 1 and experiment_name is None:
        # Single trace, legacy format
        _, metrics = all_metrics[0]
        if args.json:
            print(format_json(metrics))
        else:
            print(format_text(metrics))
    else:
        # Multiple traces or run mode, aggregated format
        if args.json:
            print(format_aggregated_json(all_metrics, experiment_name or "unknown", run_id or "unknown"))
        else:
            print(format_aggregated_text(all_metrics, experiment_name or "unknown", run_id or "unknown"))


if __name__ == "__main__":
    main()
